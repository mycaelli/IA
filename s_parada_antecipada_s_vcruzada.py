# -*- coding: utf-8 -*-
"""Código Certo 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vYoTBneW0bGhyr_uXHiI_X5fInqr-1z4
"""

import numpy as np
import os
import matplotlib.pyplot as plt


def carregar_dados():
    caminho_entrada = 'X.npy'
    caminho_saida = 'Y_classe.npy'

    dados_entrada = np.load(caminho_entrada)
    dados_saida = np.load(caminho_saida)

    dados_entrada = dados_entrada.reshape(dados_entrada.shape[0], -1)

    return dados_entrada, dados_saida

class MLP:
    def __init__(self, tamanho_cam_entrada, tamanho_cam_oculta, tamanho_cam_saida, taxa_aprendizado=0.01):
        self.tamanho_cam_oculta = tamanho_cam_oculta
        self.pesos_entrada_para_oculta = np.random.uniform(-0.5, 0.5, [tamanho_cam_entrada + 1, tamanho_cam_oculta])
        self.pesos_oculta_para_saida = np.random.uniform(-0.5, 0.5, [tamanho_cam_oculta + 1, tamanho_cam_saida])
        self.taxa_aprendizado = taxa_aprendizado

    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))

    def derivada_sigmoid(self, x):
        return x * (1 - x)

    def feedforward(self, X):
        self.cam_entrada = np.insert(X, 0, 1, axis=1)
        self.entrada_cam_oculta = np.dot(self.cam_entrada, self.pesos_entrada_para_oculta)
        self.saida_cam_oculta = self.sigmoid(self.entrada_cam_oculta)
        self.saida_cam_oculta = np.insert(self.saida_cam_oculta, 0, 1, axis=1)
        self.entrada_cam_saida = np.dot(self.saida_cam_oculta, self.pesos_oculta_para_saida)
        self.saida_cam_saida = self.sigmoid(self.entrada_cam_saida)
        return self.saida_cam_saida

    def retropropagacao(self, X, Y, saida):
        erro_saida = Y - saida
        delta_saida = erro_saida * self.derivada_sigmoid(saida)

        erro_oculta = np.dot(delta_saida, self.pesos_oculta_para_saida.T[:, 1:])
        delta_oculta = erro_oculta * self.derivada_sigmoid(self.saida_cam_oculta[:, 1:])

        self.pesos_oculta_para_saida += self.taxa_aprendizado * np.dot(self.saida_cam_oculta.T, delta_saida)
        self.pesos_entrada_para_oculta += self.taxa_aprendizado * np.dot(self.cam_entrada.T, delta_oculta)

    def treinar(self, X_teste, Y_teste, X_restante, Y_restante, epocas=1000):
        acuracias = []
        erros = []
        val_acuracias = []
        val_erros = []

        melhor_acuracia_val = 0
        epocas_sem_melhora = 0

        for epoca in range(epocas):
            saida = self.feedforward(X_teste)
            self.retropropagacao(X_teste, Y_teste, saida)

            erro = np.mean(np.square(Y_teste - saida))
            erros.append(erro)
            acuracia = self.calcular_acuracia(Y_teste, saida)
            acuracias.append(acuracia)

            val_saida = self.feedforward(X_restante)
            val_erro = np.mean(np.square(Y_restante - val_saida))
            val_erros.append(val_erro)
            val_acuracia = self.calcular_acuracia(Y_restante, val_saida)
            val_acuracias.append(val_acuracia)

        return acuracias, erros, val_acuracias, val_erros

    def prever(self, X):
        saida = self.feedforward(X)
        return saida

    def calcular_acuracia(self, Y_verdadeiro, Y_previsto):
        previsoes_corretas = np.sum(Y_verdadeiro.argmax(axis=1) == Y_previsto.argmax(axis=1))
        acuracia = previsoes_corretas / Y_verdadeiro.shape[0]
        return acuracia

    def plotar_metricas(self, acuracias, erros, val_acuracias, val_erros, diretorio_saida):
        # Plotar as acurácias de treinamento e validação
        plt.figure(figsize=(10, 6))
        plt.plot(acuracias, label='Acurácia de Treinamento')
        plt.plot(val_acuracias, label='Acurácia de Validação')
        plt.xlabel('Épocas')
        plt.ylabel('Acurácia')
        plt.title('Acurácia ao longo das Épocas')
        plt.legend()
        plt.savefig(os.path.join(diretorio_saida, "grafico_acuracia.png"))
        plt.show()

        # Plotar os erros de treinamento e validação
        plt.figure(figsize=(10, 6))
        plt.plot(erros, label='Erro de Treinamento')
        plt.plot(val_erros, label='Erro de Validação')
        plt.xlabel('Épocas')
        plt.ylabel('Erro')
        plt.title('Erro de Treinamento e Validação ao longo das Épocas')
        plt.legend()
        plt.savefig(os.path.join(diretorio_saida, "grafico_erro.png"))
        plt.show()

    def plotar_matriz_confusao(self, Y_verdadeiro, Y_previsto, diretorio_saida):
        matriz_confusao = np.zeros((Y_verdadeiro.shape[1], Y_verdadeiro.shape[1]), dtype=int)
        for verdadeiro, previsto in zip(Y_verdadeiro.argmax(axis=1), Y_previsto.argmax(axis=1)):
            matriz_confusao[verdadeiro, previsto] += 1

        plt.figure(figsize=(10, 6))
        plt.imshow(matriz_confusao, interpolation='nearest', cmap=plt.cm.Blues)
        plt.title('Matriz de Confusão')
        plt.colorbar()
        marcas_tick = np.arange(Y_verdadeiro.shape[1])
        plt.xticks(marcas_tick, marcas_tick, rotation=45)
        plt.yticks(marcas_tick, marcas_tick)

        limiar = matriz_confusao.max() / 2.
        for i, j in np.ndindex(matriz_confusao.shape):
            plt.text(j, i, format(matriz_confusao[i, j], 'd'),
                     horizontalalignment="center",
                     color="white" if matriz_confusao[i, j] > limiar else "black")

        plt.ylabel('Rótulo Verdadeiro')
        plt.xlabel('Rótulo Previsto')
        plt.tight_layout()
        plt.savefig(os.path.join(diretorio_saida, "matriz_confusao.png"))
        plt.show()

def busca_em_grade(X, Y, grid_parametros):
    melhores_parametros = None
    melhor_acuracia = 0
    resultados = []

    num_folds = 5
    tamanho_fold = len(X) // num_folds

    for taxa_aprendizado in grid_parametros['taxa_aprendizado']:
        for tamanho_cam_oculta in grid_parametros['tamanho_cam_ocultas']:
            acuracias_fold = []
            for fold in range(num_folds):
                inicio = fold * tamanho_fold
                fim = (fold + 1) * tamanho_fold if fold != num_folds - 1 else len(X)

                X_val_fold = X[inicio:fim]
                Y_val_fold = Y[inicio:fim]
                X_treinamento_fold = np.concatenate([X[:inicio], X[fim:]])
                Y_treinamento_fold = np.concatenate([Y[:inicio], Y[fim:]])

                mlp = MLP(tamanho_cam_entrada=X_treinamento_fold.shape[1], tamanho_cam_oculta=tamanho_cam_oculta,
                          tamanho_cam_saida=Y_treinamento_fold.shape[1], taxa_aprendizado=taxa_aprendizado)
                _, _, val_acuracias, _ = mlp.treinar(X_treinamento_fold, Y_treinamento_fold, X_val_fold, Y_val_fold, epocas=2000)
                acuracias_fold.append(np.mean(val_acuracias))

            media_val_acuracia = np.mean(acuracias_fold)
            resultados.append({
                'taxa_aprendizado': taxa_aprendizado,
                'tamanho_cam_oculta': tamanho_cam_oculta,
                'val_acuracia': media_val_acuracia
            })

            if media_val_acuracia > melhor_acuracia:
                melhor_acuracia = media_val_acuracia
                melhores_parametros = {'taxa_aprendizado': taxa_aprendizado, 'tamanho_cam_oculta': tamanho_cam_oculta}

    return melhores_parametros, resultados

# Criar o diretório de saída, se não existir
diretorio_saida = './arquivos_de_saida'
if not os.path.exists(diretorio_saida):
    os.makedirs(diretorio_saida)

# Carregar os dados
X, Y = carregar_dados()

# Normalização dos dados
escalador = lambda x: (x - np.mean(x, axis=0)) / np.std(x, axis=0)
X = escalador(X)

# Manter os últimos 130 valores para teste
X_teste = X[-130:]
Y_teste = Y[-130:]
X_restante = X[:-130]
Y_restante = Y[:-130]

# Listas para armazenar os resultados de cada fold
todas_acuracias = []
todos_erros = []
todas_val_acuracias = []
todos_val_erros = []

# Definir a grade de parâmetros para o Grid Search
grid_parametros = {
    'taxa_aprendizado': [0.001, 0.005, 0.01],
    'tamanho_cam_ocultas': [20, 40, 60]
}

# Executar o Grid Search
melhores_parametros, resultados = busca_em_grade(X_teste, Y_teste, grid_parametros)

# Exibir os melhores parâmetros
print("Melhores parâmetros encontrados:", melhores_parametros)

# Treinar o MLP com os dados completos de treinamento e validação
mlp = MLP(tamanho_cam_entrada=120, tamanho_cam_oculta=20, tamanho_cam_saida=26, taxa_aprendizado=0.01)
pesos_iniciais = {'pesos_entrada_para_oculta': mlp.pesos_entrada_para_oculta.copy(), 'pesos_oculta_para_saida': mlp.pesos_oculta_para_saida.copy()}
acuracias, erros, val_acuracias, val_erros = mlp.treinar(X_teste, Y_teste, X_restante, Y_restante, epocas=2000)
# Plotar as métricas
mlp.plotar_metricas(acuracias, erros, val_acuracias, val_erros, diretorio_saida)
pesos_finais = {'pesos_entrada_para_oculta': mlp.pesos_entrada_para_oculta, 'pesos_oculta_para_saida': mlp.pesos_oculta_para_saida}

# Fazer previsões no conjunto de teste
previsoes_teste = mlp.prever(X_teste)

# Calcular a acurácia no conjunto de teste
acuracia_teste = mlp.calcular_acuracia(Y_teste, previsoes_teste)
print(f"Acurácia no conjunto de teste: {acuracia_teste}")

# Plotar a matriz de confusão para o conjunto de teste
mlp.plotar_matriz_confusao(Y_teste, previsoes_teste, diretorio_saida)

# Salvar hiperparâmetros
hiperparametros = {
    "tamanho_cam_entrada": 120,
    "tamanho_cam_oculta": melhores_parametros['tamanho_cam_oculta'],
    "tamanho_cam_saida": 26,
    "taxa_aprendizado": melhores_parametros['taxa_aprendizado'],
    "epocas": 2000
}

with open(os.path.join(diretorio_saida, "hiperparametros.txt"), "w") as f:
    for chave, valor in hiperparametros.items():
        f.write(f"{chave}: {valor}\n")