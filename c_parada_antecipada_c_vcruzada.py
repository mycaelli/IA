# -*- coding: utf-8 -*-
"""Código Certo 4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vYoTBneW0bGhyr_uXHiI_X5fInqr-1z4
"""

import numpy as np
import os
import matplotlib.pyplot as plt

def carregar_dados():
    path_x = 'X.npy'
    path_y = 'Y_classe.npy'

    dados_entrada = np.load(path_x)
    dados_saida = np.load(path_y)

    dados_entrada = dados_entrada.reshape(dados_entrada.shape[0], -1)

    return dados_entrada, dados_saida

class MLP:
    def __init__(self, tam_cam_entrada, tam_camada_oculta, tam_camada_saida, taxa_aprendizado=0.01):
        self.tam_camada_oculta = tam_camada_oculta
        self.pesos_entrada_para_oculta = np.random.uniform(-0.5, 0.5, [tam_cam_entrada + 1, tam_camada_oculta])
        self.pesos_oculta_para_saida = np.random.uniform(-0.5, 0.5, [tam_camada_oculta + 1, tam_camada_saida])
        self.taxa_aprendizado = taxa_aprendizado

    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))

    def derivada_sigmoid(self, x):
        return x * (1 - x)

    def feedforward(self, X):
        self.cam_entrada = np.insert(X, 0, 1, axis=1)
        self.entrada_cam_oculta = np.dot(self.cam_entrada, self.pesos_entrada_para_oculta)
        self.saida_cam_oculta = self.sigmoid(self.entrada_cam_oculta)
        self.saida_cam_oculta = np.insert(self.saida_cam_oculta, 0, 1, axis=1)
        self.entrada_cam_saida = np.dot(self.saida_cam_oculta, self.pesos_oculta_para_saida)
        self.saida_cam_saida = self.sigmoid(self.entrada_cam_saida)
        return self.saida_cam_saida

    def retropropagacao(self, X, Y, saida):
        erro_saida = Y - saida
        delta_saida = erro_saida * self.derivada_sigmoid(saida)

        erro_oculta = np.dot(delta_saida, self.pesos_oculta_para_saida.T[:, 1:])
        delta_oculta = erro_oculta * self.derivada_sigmoid(self.saida_cam_oculta[:, 1:])

        self.pesos_oculta_para_saida += self.taxa_aprendizado * np.dot(self.saida_cam_oculta.T, delta_saida)
        self.pesos_entrada_para_oculta += self.taxa_aprendizado * np.dot(self.cam_entrada.T, delta_oculta)

    def treinar(self, X_treinamento, Y_treinamento, X_validacao, Y_validacao, epocas=1000, early_stopping_rounds=50):
        acuracias = []
        erros = []
        val_acuracias = []
        val_erros = []

        melhor_val_acuracia = 0
        epocas_sem_melhora = 0

        for epoca in range(epocas):
            saida = self.feedforward(X_treinamento)
            self.retropropagacao(X_treinamento, Y_treinamento, saida)

            erro = np.mean(np.square(Y_treinamento - saida))
            erros.append(erro)
            acuracia = self.calcular_acuracia(Y_treinamento, saida)
            acuracias.append(acuracia)

            val_saida = self.feedforward(X_validacao)
            val_erro = np.mean(np.square(Y_validacao - val_saida))
            val_erros.append(val_erro)
            val_acuracia = self.calcular_acuracia(Y_validacao, val_saida)
            val_acuracias.append(val_acuracia)

            if val_acuracia > melhor_val_acuracia:
                melhor_val_acuracia = val_acuracia
                epocas_sem_melhora = 0
            else:
                epocas_sem_melhora += 1

            if epocas_sem_melhora >= early_stopping_rounds:
                print(f'Early stopping at epoch {epoca}')
                break

        return acuracias, erros, val_acuracias, val_erros

    def prediz_acuracia(self, X):
        saida = self.feedforward(X)
        return saida

    def calcular_acuracia(self, Y_verdadeiro, Y_previsto):
        previsoes_corretas = np.sum(Y_verdadeiro.argmax(axis=1) == Y_previsto.argmax(axis=1))
        acuracia = previsoes_corretas / Y_verdadeiro.shape[0]
        return acuracia

    def plotar_metricas(self, acuracias, erros, val_acuracias, val_erros, fold, diretorio_saida):
        # Plotar as acurácias de treinamento e validação
        plt.figure(figsize=(10, 6))
        plt.plot(acuracias, label=f'Acurácia de Treinamento - Fold {fold}')
        plt.plot(val_acuracias, label=f'Acurácia de Validação - Fold {fold}')
        plt.xlabel('Épocas')
        plt.ylabel('Acurácia')
        plt.title(f'Acurácia ao longo das Épocas - Fold {fold}')
        plt.legend()
        plt.savefig(os.path.join(diretorio_saida, f"grafico_acuracia_fold_{fold}.png"))
        plt.show()

        # Plotar os erros de treinamento e validação
        plt.figure(figsize=(10, 6))
        plt.plot(erros, label=f'Erro de Treinamento - Fold {fold}')
        plt.plot(val_erros, label=f'Erro de Validação - Fold {fold}')
        plt.xlabel('Épocas')
        plt.ylabel('Erro')
        plt.title(f'Erro de Treinamento e Validação ao longo das Épocas - Fold {fold}')
        plt.legend()
        plt.savefig(os.path.join(diretorio_saida, f"grafico_erro_fold_{fold}.png"))
        plt.show()

    def plotar_matriz_confusao(self, Y_verdadeiro, Y_previsto, fold, diretorio_saida):
        matriz_confusao = np.zeros((Y_verdadeiro.shape[1], Y_verdadeiro.shape[1]), dtype=int)
        for verdadeiro, previsto in zip(Y_verdadeiro.argmax(axis=1), Y_previsto.argmax(axis=1)):
            matriz_confusao[verdadeiro, previsto] += 1

        plt.figure(figsize=(10, 6))
        plt.imshow(matriz_confusao, interpolation='nearest', cmap=plt.cm.Blues)
        plt.title(f'Matriz de Confusão - Fold {fold}')
        plt.colorbar()
        marcas_tick = np.arange(Y_verdadeiro.shape[1])
        plt.xticks(marcas_tick, marcas_tick, rotation=45)
        plt.yticks(marcas_tick, marcas_tick)

        limiar = matriz_confusao.max() / 2.
        for i, j in np.ndindex(matriz_confusao.shape):
            plt.text(j, i, format(matriz_confusao[i, j], 'd'),
                     horizontalalignment="center",
                     color="white" if matriz_confusao[i, j] > limiar else "black")

        plt.ylabel('Rótulo Verdadeiro')
        plt.xlabel('Rótulo Previsto')
        plt.tight_layout()
        plt.savefig(os.path.join(diretorio_saida, f"matriz_confusao_fold_{fold}.png"))
        plt.show()

# Criar o diretório de saída, se não existir
diretorio_saida = 'C:\\Users\\gui02\\Downloads\\EP IA\\IA-main\\arquivos de saida'
if not os.path.exists(diretorio_saida):
    os.makedirs(diretorio_saida)

# Carregar os dados
X, Y = carregar_dados()

# Normalização dos dados
escalador = lambda x: (x - np.mean(x, axis=0)) / np.std(x, axis=0)
X = escalador(X)

# Manter os últimos 130 valores para teste
X_teste = X[-130:]
Y_teste = Y[-130:]
X_restante = X[:-130]
Y_restante = Y[:-130]

# Dividir os dados restantes em treino (60%) e validação (40%) manualmente
def dividir_dados_manual(X, Y, tamanho_teste):
    n_treinamento = int((1 - tamanho_teste) * X.shape[0])
    indices = np.random.permutation(X.shape[0])
    indices_treinamento = indices[:n_treinamento]
    indices_validacao = indices[n_treinamento:]
    return X[indices_treinamento], X[indices_validacao], Y[indices_treinamento], Y[indices_validacao]

X_treinamento, X_validacao, Y_treinamento, Y_validacao = dividir_dados_manual(X_restante, Y_restante, tamanho_teste=0.4)

# Configurar validação cruzada manualmente
def validacao_cruzada_manual(X, Y, num_folds):
    indices = np.random.permutation(X.shape[0])
    tamanho_fold = X.shape[0] // num_folds
    folds = []
    for i in range(num_folds):
        inicio = i * tamanho_fold
        fim = (i + 1) * tamanho_fold if i != num_folds - 1 else X.shape[0]
        folds.append((indices[inicio:fim], np.concatenate((indices[:inicio], indices[fim:]))))
    return folds

num_folds = 5
folds = validacao_cruzada_manual(X_treinamento, Y_treinamento, num_folds)

# Listas para armazenar os resultados de cada fold
todas_acuracias = []
todos_erros = []
todas_val_acuracias = []
todos_val_erros = []

fold = 1
for indices_validacao, indices_treinamento in folds:
    X_treinamento_fold, X_validacao_fold = X_treinamento[indices_treinamento], X_treinamento[indices_validacao]
    Y_treinamento_fold, Y_validacao_fold = Y_treinamento[indices_treinamento], Y_treinamento[indices_validacao]

    mlp = MLP(tam_cam_entrada=120, tam_camada_oculta=20, tam_camada_saida=26, taxa_aprendizado=0.01)
    acuracias, erros, val_acuracias, val_erros = mlp.treinar(X_treinamento_fold, Y_treinamento_fold, X_validacao_fold, Y_validacao_fold, epocas=2000, early_stopping_rounds=50)

    # Plotar as métricas
    mlp.plotar_metricas(acuracias, erros, val_acuracias, val_erros, fold, diretorio_saida)

    # Previsões para matriz de confusão
    val_previsoes = mlp.prediz_acuracia(X_validacao_fold)
    mlp.plotar_matriz_confusao(Y_validacao_fold, val_previsoes, fold, diretorio_saida)

    # Armazenar os resultados de cada fold
    todas_acuracias.append(acuracias)
    todos_erros.append(erros)
    todas_val_acuracias.append(val_acuracias)
    todos_val_erros.append(val_erros)

    fold += 1

# Treinar o MLP com os dados completos de treinamento e validação
mlp_final = MLP(tam_cam_entrada=120, tam_camada_oculta=20, tam_camada_saida=26, taxa_aprendizado=0.01)
mlp_final.treinar(X_treinamento, Y_treinamento, X_validacao, Y_validacao, epocas=2000, early_stopping_rounds=50)

# Fazer previsões no conjunto de teste
previsoes_teste = mlp_final.prediz_acuracia(X_teste)

# Calcular a acurácia no conjunto de teste
acuracia_teste = mlp_final.calcular_acuracia(Y_teste, previsoes_teste)
print(f"Acurácia no conjunto de teste: {acuracia_teste}")

# Plotar a matriz de confusão para o conjunto de teste
mlp_final.plotar_matriz_confusao(Y_teste, previsoes_teste, 'Teste', diretorio_saida)

# Salvar hiperparâmetros
hiperparametros = {
    "tam_cam_entrada": 120,
    "tam_camada_oculta": 20,
    "tam_camada_saida": 26,
    "taxa_aprendizado": 0.01,
    "epocas": 2000
}
with open(os.path.join(diretorio_saida, "hiperparametros.txt"), "w") as f:
    for chave, valor in hiperparametros.items():
        f.write(f"{chave}: {valor}\n")